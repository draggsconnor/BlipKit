---
layout: doc
title: Introduction
order: 0
---

There are two base objects:

The [`BKContext`](context/) object contains the audio buffers in which the audio data is rendered. Each channel has its own audio buffer. For example, left and right for stereo.

[`BKTrack`](track/) objects render the audio data. This may be a waveform or a loaded sample. Each context may have an arbitrary number of tracks attached to it.

Sound is generated by requesting frames. This is done by calling either [`BKContextGenerate`](), which fills a provided buffer with the requested number of frames, or its variant [`BKContextGenerateToTime`](), which outputs the frames to a provided callback. Each call to one of this functions advances each attached track's time by running their render functions. Subsequent calls to the generator functions generate the next requested number of frames.
