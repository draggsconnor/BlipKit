---
layout: doc
title: Introduction
order: 0
---

There are two base objects:

The [`BKContext`](../context/) object contains the audio buffers in which the audio data is rendered. Each channel has its own audio buffer. For example, left and right for stereo.

[`BKTrack`](../track/) objects render the audio data. This may be a waveform or a loaded sample. Each context may have an arbitrary number of tracks attached to it.

Sound is generated by requesting frames. This is done by calling either [`BKContextGenerate`](../context/#bkcontextgenerate), which fills a provided buffer with the requested number of frames, or its variant [`BKContextGenerateToTime`](../context/#bkcontextgeneratetotime), which outputs the frames to a provided callback. A call to one of this functions advances each attached track's time by running its render function. Subsequent calls to the generator functions generate the next requested number of frames.
